{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tvanzyl/miniforge3/envs/saccadic-jepa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from lightly.data import LightlyDataset\n",
    "import SimPLR\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"SimPLR\"\n",
    "train_dir = \"/media/tvanzyl/data/tiny-imagenet-200/train\"\n",
    "batch_size_per_device = 256\n",
    "num_workers = 1\n",
    "ckpt_path = \"./benchmark_logs/SimPLR/2025-03-25_17-57-47/pretrain/version_0/checkpoints/epoch=199-step=78000.ckpt\"\n",
    "num_classes=200\n",
    "resnetsize=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = {\n",
    "    \"SimPLR\": {\"model\": SimPLR.SimPLR, \"transform\": SimPLR.transform},\n",
    "}\n",
    "model = METHODS[method][\"model\"](\n",
    "            batch_size_per_device=batch_size_per_device, num_classes=num_classes, resnetsize=resnetsize\n",
    "        )\n",
    "train_transform = METHODS[method][\"transform\"]\n",
    "\n",
    "train_dataset = LightlyDataset(input_dir=str(train_dir), transform=train_transform)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_per_device,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    persistent_workers=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1754610/3608797432.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, targets, _ = train_dataloader.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = model.backbone(x[0]).flatten(start_dim=1)\n",
    "f1 = model.backbone(x[1]).flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.9030, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.criterion(g0, g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = model.projection_head(f0)\n",
    "g1 = model.projection_head(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = model.merge_head(g0)\n",
    "z1 = model.merge_head(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = model.prediction_head(g0)\n",
    "p1 = model.prediction_head(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0000, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.criterion(p0, z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0000, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.criterion(p1, z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0000, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.criterion(SimPLR.L2NormalizationLayer().forward(model.prediction_head(g0)),model.merge_head(g0*0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., -0.,  ..., -0., 0., 0.],\n",
       "        [0., 0., -0.,  ..., -0., 0., 0.],\n",
       "        [0., 0., -0.,  ..., -0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., -0.,  ..., -0., 0., 0.],\n",
       "        [0., 0., -0.,  ..., -0., 0., 0.],\n",
       "        [0., 0., -0.,  ..., -0., 0., 0.]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimPLR.L2NormalizationLayer().forward(0.0*model.prediction_head(g0))/2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0251,  0.0407, -0.0356,  ..., -0.0188, -0.0062,  0.0054],\n",
       "        [ 0.0379,  0.0087, -0.0107,  ..., -0.0078, -0.0073,  0.0118],\n",
       "        [ 0.0385,  0.0042, -0.0040,  ..., -0.0066, -0.0119,  0.0148],\n",
       "        ...,\n",
       "        [ 0.0390,  0.0048, -0.0008,  ..., -0.0037, -0.0118,  0.0150],\n",
       "        [ 0.0308,  0.0339, -0.0362,  ..., -0.0197, -0.0032,  0.0066],\n",
       "        [ 0.0389,  0.0124, -0.0153,  ..., -0.0095, -0.0049,  0.0116]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.merge_head(g1*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0237,  0.0430, -0.0356,  ..., -0.0189, -0.0074,  0.0044],\n",
       "        [ 0.0374,  0.0072, -0.0094,  ..., -0.0077, -0.0083,  0.0124],\n",
       "        [ 0.0382,  0.0041, -0.0059,  ..., -0.0082, -0.0115,  0.0146],\n",
       "        ...,\n",
       "        [ 0.0384,  0.0075, -0.0047,  ..., -0.0045, -0.0089,  0.0125],\n",
       "        [ 0.0341,  0.0270, -0.0301,  ..., -0.0161, -0.0025,  0.0082],\n",
       "        [ 0.0385,  0.0066, -0.0054,  ..., -0.0050, -0.0098,  0.0130]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.merge_head(g0*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_, p, z = model.forward_student( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n",
      "tensor(-0.1250, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "for i in range(8):\n",
    "    print(model.criterion(p[i], z[i]) / model.ens_size)\n",
    "    l += model.criterion(p[i], z[i]) / model.ens_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saccadic-jepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
